# -*- coding: utf-8 -*-
"""MNIST_fashion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16fhQl202LeNZP_Wd6D2J1Drpb20Cg1ys
"""

import warnings
warnings.filterwarnings('ignore')
import pickle
import numpy as np
import pandas as pd
import json
import nltk
from textblob import TextBlob
import spacy
import matplotlib.pyplot as plt
import cv2
from sklearn.datasets import make_circles
import keras

from google.colab import drive 
drive.mount('/content/gdrive')

import matplotlib
import matplotlib.pyplot as plt
import numpy as np
from keras.utils import to_categorical
from keras import models
from keras import layers
import cv2
from sklearn.datasets import make_circles

from keras.models import Sequential
from keras.layers import Dense
from keras import models
model = models.Sequential()

X,Y = make_circles(n_samples=500,shuffle=True,noise=0.05,random_state=1,factor=0.8)
X.shape

model.add(Dense(units=2, activation='relu', input_dim=2))
model.add(Dense(units=10, activation='relu'))
model.add(Dense(units=5, activation='relu'))
model.add(Dense(units=1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

split=int(0.8*X.shape[0])
x_train=X[:split,:]
x_test=X[split:,:]
y_test=Y[split:]
y_train=Y[:split]
print(x_train.shape)
print(y_train.shape)
x_train=np.array(x_train)
y_train=np.array(y_train)

history=model.fit(x_train, y_train, epochs=1000, batch_size=8)

score = model.evaluate(x_test, y_test, verbose=1)

print(score)

history.history.keys()

plt.style.use("seaborn")
plt.plot(history.history['loss'])
plt.show()

fashion_mnist = keras.datasets.fashion_mnist
(train_images,train_labels) , (test_images,test_labels) = fashion_mnist.load_data()

print(train_labels)

print(train_labels.shape)

print(train_images.shape)

import cv2

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

plt.figure()
img_=train_images[0]
img_ = img_.reshape((28,28))
plt.imshow(img_)
plt.colorbar()
plt.grid(False)

train_images = train_images / 255.0

test_images = test_images / 255.0

plt.figure(figsize=(1,1))
img_=train_images[0]
img_ = img_.reshape((28,28))
plt.imshow(img_)
plt.colorbar()
plt.grid(False)

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])

import tensorflow as tf
modell = models.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

modell.compile(optimizer=tf.train.AdamOptimizer(), 
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

modell.fit(train_images, train_labels, epochs=5)

test_loss, test_acc = modell.evaluate(test_images, test_labels)

print('Test accuracy:', test_acc)

predictions = modell.predict(test_images)

print(predictions.shape)

print(predictions)

test_labels.shape

predictions[0]

pred_ = []
for i in range(test_images.shape[0]):
  pred_.append(np.argmax(predictions[i]))

np.sum(pred_==test_labels)/float(test_labels.shape[0])

